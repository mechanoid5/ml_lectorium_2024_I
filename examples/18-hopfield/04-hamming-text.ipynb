{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**сеть Хемминга**\n",
    "\n",
    "нечёткий поиск по словарю\n",
    "\n",
    "Евгений Борисов esborisov@sevsu.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А.Арустамов, А.Стариков    Ассоциативная память.Применение сетей Хемминга для нечеткого поиска.   \n",
    "https://basegroup.ru/community/articles/assoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  загружаем данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def read_list_txt(fname):\n",
    "    with gzip.open(fname,'rt') as f: \n",
    "        return [ w.strip() for w in f.read().split('\\n') if w.strip() ]\n",
    "        \n",
    "ideal = read_list_txt('data/ideal_u.txt.gz')\n",
    "\n",
    "max_word_len = max([len(w) for w in ideal]) # максимальная длинна слова словаре\n",
    "voc_len = len(ideal) # размер словаря\n",
    "\n",
    "voc_len, max_word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## кодируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кодирование строится таким образом, \n",
    "# что бы стоящие рядом на компьютерной клавиатуре символы \n",
    "# имели близкие по Хеммингу коды.\n",
    "# Таким образом должно достигаться наиболее эффективное исправление опечаток.\n",
    "CODE_A = {\n",
    "   'к':(0,0,0,0,0,),\n",
    "   'ж':(0,0,0,0,1,),\n",
    "   'г':(0,0,0,1,0,),\n",
    "   'щ':(0,0,0,1,1,),\n",
    "   'ч':(0,0,1,0,0,),\n",
    "   'х':(0,0,1,0,1,),\n",
    "   'ю':(0,0,1,1,0,),\n",
    "   'с':(0,0,1,1,1,),\n",
    "   'у':(0,1,0,0,0,),\n",
    "   'б':(0,1,0,0,1,),\n",
    "   'л':(0,1,0,1,0,),\n",
    "   'е':(0,1,0,1,1,),\n",
    "   'о':(0,1,1,0,0,),\n",
    "   'р':(0,1,1,0,1,),\n",
    "   'н':(0,1,1,1,0,),\n",
    "   'й':(0,1,1,1,1,),\n",
    "   'т':(1,0,0,0,0,),\n",
    "   'з':(1,0,0,0,1,),\n",
    "   'ы':(1,0,0,1,0,),\n",
    "   'п':(1,0,0,1,1,),\n",
    "   'ф':(1,0,1,0,0,),\n",
    "   'ш':(1,0,1,0,1,),\n",
    "   'м':(1,0,1,1,0,),\n",
    "   'э':(1,0,1,1,1,),\n",
    "   'ъ':(1,1,0,0,0,),\n",
    "   'д':(1,1,0,0,1,),\n",
    "   'в':(1,1,0,1,0,),\n",
    "   'а':(1,1,0,1,1,),\n",
    "   'ц':(1,1,1,0,0,),\n",
    "   'и':(1,1,1,0,1,),\n",
    "   'я':(1,1,1,1,0,),\n",
    "   'ь':(1,1,1,1,1,)\n",
    "}\n",
    "\n",
    "CODE_V = { CODE_A[a]:a for a in CODE_A }\n",
    "\n",
    "def encode(w): return  [ CODE_A[a] for a in list(w.lower()) ]\n",
    "def decode(c): return  [ CODE_V[v] for v in c ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_len = len(CODE_A['а']) # длинна кода символа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменяем буквы на коды\n",
    "def encode_text(text):\n",
    "    return [ encode(w) for w in text]\n",
    "\n",
    "# обрезаем длиные слова\n",
    "def strip_text(text,max_word=0): \n",
    "    return [ w[:max_word_len] for w in text ] \n",
    "\n",
    "# дополняем коды коротких слов нулями\n",
    "def pad_code(x,max_word=0): \n",
    "    code_len = len(x[0][0]) # длинна кода\n",
    "    # максимальная длинна слова\n",
    "    mwl = max([len(v) for v in x]) if max_word<1 else max_word\n",
    "    # дополнение нулями\n",
    "    z = [(0,)*code_len]*mwl\n",
    "    # дополняем короткое слово\n",
    "    return [ v + z[:(mwl-len(v))] for v in x ]\n",
    "\n",
    "# собираем датасет из списка слов text,\n",
    "# max_word - ограничение максимальной длины слова (0 - нет ограничений)\n",
    "def make_dataset(text,max_word=0):\n",
    "    t = strip_text(text,max_word) \n",
    "    x = encode_text(t)\n",
    "    x = pad_code(x,max_word)\n",
    "    return np.array([ sum(v,()) for v in x ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = make_dataset(ideal)   \n",
    "\n",
    "# масштабируем в [-1,+1]\n",
    "x_train = x_train*2-1\n",
    "\n",
    "display(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загружаем память сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сеть Хэминга\n",
    "\n",
    "![neural-net-hamming](http://mechanoid.su/content/neural-net-hamming-classifier.html/nnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HammingNet:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._weight_lin = 0.\n",
    "        self._weight_hop = 0.\n",
    "        \n",
    "    def fit(self,x):\n",
    "        self._weight_lin =  0.5*x.T\n",
    "        \n",
    "        n_samples,_ = x.shape # количество учебных примеров \n",
    "        c = 1./(2.*n_samples) # коэффициент торможения\n",
    "        # веса для нейронов второго слоя\n",
    "        self._weight_hop = -c*(np.ones(n_samples)-np.eye(n_samples)) + np.eye(n_samples)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def forward(self,x,max_iter=8):\n",
    "        o = x.dot(self._weight_lin)\n",
    "        for n in range(max_iter):\n",
    "            o_ = o.copy() # сохраняем состояние\n",
    "            o = self._forward_step(o) # переходим в новое состояние\n",
    "            # если состояние не изменилось то завершаем\n",
    "            if np.all(o==o_): break\n",
    "        return n,o        \n",
    "    \n",
    "    def _forward_step(self,x):\n",
    "        return np.max( [x.dot(self._weight_hop), np.zeros(x.shape)],axis=0 )\n",
    "    \n",
    "    def __call__(self,x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def predict(self,x):\n",
    "        n,o = self.forward(x)\n",
    "        return n,np.argmax(o,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HammingNet().fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_list_txt('data/test_u.txt.gz')\n",
    "display( len(test) )\n",
    "display( test[:7] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_word_len = max([len(w) for w in ideal])\n",
    "x_test = make_dataset(test,max_word=max_word_len)    \n",
    "x_test = x_test*2-1\n",
    "display( x_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate \n",
    "\n",
    "_,p = model.predict(x_test)\n",
    "res = [ [t, ideal[p[i]] ] for i,t in enumerate(test) ]\n",
    "\n",
    "tabulate(res, tablefmt='html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
