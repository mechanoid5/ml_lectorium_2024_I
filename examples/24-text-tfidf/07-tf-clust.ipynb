{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**кластеризатор текстов**\n",
    "\n",
    "SnowballStemmer + TFIDF + DBSCAN\n",
    "\n",
    "_Евгений Борисов <esborisov@sevsu.ru>_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pd.options.display.precision = 2 \n",
    "pd.options.display.max_colwidth = 200 \n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "датасет news.pkl.gz   \n",
    "https://disk.yandex.ru/d/8_T_XITkZ4gKAw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>В калифорнийском метро нашли останки мастодонтов возрастом 10 тысяч лет\\n\\n2 декабря 2016 в 18:37\\n\\nLenta.ru\\n\\nВо время работ по расширению метро Лос-Анджелеса, штат Калифорния, рабочие наткнули...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Фестиваль военно-патриотических фильмов проходит в Подмосковье\\n(3)\"Волоколамский рубеж\" - так называется международный фестиваль\\nвоенно-патриотического фильма им. Сергея Бондарчука, который втор...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         text  \\\n",
       "1335  В калифорнийском метро нашли останки мастодонтов возрастом 10 тысяч лет\\n\\n2 декабря 2016 в 18:37\\n\\nLenta.ru\\n\\nВо время работ по расширению метро Лос-Анджелеса, штат Калифорния, рабочие наткнули...   \n",
       "321   Фестиваль военно-патриотических фильмов проходит в Подмосковье\\n(3)\"Волоколамский рубеж\" - так называется международный фестиваль\\nвоенно-патриотического фильма им. Сергея Бондарчука, который втор...   \n",
       "\n",
       "          tag  \n",
       "1335     tech  \n",
       "321   culture  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# загружаем тексты\n",
    "data = pd.read_pickle('news.pkl.gz')\n",
    "display( len(data) )\n",
    "display(  data.sample(2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( len( data.drop_duplicates('text') ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK package manager\n",
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from nltk.tokenize import word_tokenize as nltk_tokenize_word\n",
    "\n",
    "# def tokenizer(text):\n",
    "#     return [\n",
    "#             t for t in nltk_tokenize_word( # разбиваем текст на слова\n",
    "#                 re.sub(r'</?[a-z]+>',' ',text), # удаляем xml tag \n",
    "#                 language='russian'\n",
    "#             ) \n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# from nltk.tokenize import word_tokenize as nltk_tokenize_word\n",
    "# from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "# stopwords = set(nltk_stopwords.words('russian'))\n",
    "\n",
    "# def tokenizer(text,stopwords=stopwords):\n",
    "#     return [\n",
    "#             t for t in nltk_tokenize_word( # разбиваем текст на слова\n",
    "#                 re.sub(r'</?[a-z]+>',' ',text), # удаляем xml tag \n",
    "#                 language='russian'\n",
    "#             ) \n",
    "#             if not (\n",
    "#                False\n",
    "#                or (len(t)<3) # выкидываем очень короткие слова\n",
    "#                or re.match(r'^[^a-zA-ZЁёА-я]+$', t) # выкидываем токены не содержащие букв\n",
    "#                or re.match(r'^(\\w)\\1+$', t)  # выкидываем токены из одного повторяющегося символа\n",
    "#                or re.match(r'^[^a-zA-ZЁёА-я].*$', t)  # выкидываем токены начинающиеся не с буквы\n",
    "#                or (t in stopwords) # выкидываем предлоги, союзы и т.п.    \n",
    "#             )\n",
    "#         ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# from razdel import sentenize\n",
    "from razdel import tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "stopwords = set(nltk_stopwords.words('russian'))\n",
    "\n",
    "def tokenizer(text,stopwords=stopwords):\n",
    "    return [\n",
    "            t.text for t in tokenize( # разбиваем текст на слова\n",
    "                re.sub(r'</?[a-z]+>',' ',text), # удаляем xml tag \n",
    "            ) \n",
    "            if not (\n",
    "               False\n",
    "               or (len(t.text)<3) # выкидываем очень короткие слова\n",
    "               or re.match(r'^[^a-zA-ZЁёА-я]+$', t.text) # выкидываем токены не содержащие букв\n",
    "               or re.match(r'^(\\w)\\1+$', t.text)  # выкидываем токены из одного повторяющегося символа\n",
    "               or re.match(r'^[^a-zA-ZЁёА-я].*$', t.text)  # выкидываем токены начинающиеся не с буквы\n",
    "               or (t.text in stopwords) # выкидываем предлоги, союзы и т.п.    \n",
    "            )\n",
    "        ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## выполняем частотный анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# tf_model = CountVectorizer(\n",
    "#         min_df=.01, # выкидываем очень редкие слова\n",
    "#         max_df=.25, # выкидываем очень частые слова\n",
    "#         tokenizer=tokenizer, # ф-ция токенайзер\n",
    "#         token_pattern=None, # отключаем дефолтный токенайзер\n",
    "#         binary=True,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_model = TfidfVectorizer(\n",
    "        min_df=.01, # выкидываем очень редкие слова\n",
    "        max_df=.10, # выкидываем очень частые слова\n",
    "        use_idf=False, # не используем обратную частоту\n",
    "        norm='l2', # нормируем TF\n",
    "        tokenizer=tokenizer, # ф-ция токенайзер\n",
    "        token_pattern=None, # отключаем дефолтный токенайзер\n",
    "        ngram_range = (2,2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3196, 116)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.39 s, sys: 60.9 ms, total: 4.45 s\n",
      "Wall time: 4.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_tf = tf_model.fit_transform( data['text'].str.lower() )\n",
    "\n",
    "display(data_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['adobe flash',\n",
       " 'afisha tut',\n",
       " 'auto tut',\n",
       " 'finance tut',\n",
       " 'flash player',\n",
       " 'html установлена',\n",
       " 'javascript ваш',\n",
       " 'realty tut',\n",
       " 'sport tut',\n",
       " 'wall street',\n",
       " 'ближайшее время',\n",
       " 'большая часть',\n",
       " 'браузер поддерживает',\n",
       " 'ваш браузер',\n",
       " 'версия проигрывателя',\n",
       " 'владимир путин',\n",
       " 'внимание отключен',\n",
       " 'возбуждено уголовное',\n",
       " 'вторник декабря',\n",
       " 'второе место',\n",
       " 'глава государства',\n",
       " 'главы государства',\n",
       " 'говорится сообщении',\n",
       " 'года назад',\n",
       " 'данный момент',\n",
       " 'дек риа',\n",
       " 'декабря auto',\n",
       " 'декабря lenta',\n",
       " 'декабря sport',\n",
       " 'декабря tut',\n",
       " 'декабря года',\n",
       " 'декабря обновлено',\n",
       " 'декабря тасс',\n",
       " 'дональд трамп',\n",
       " 'дональда трампа',\n",
       " 'друг друга',\n",
       " 'избранного президента',\n",
       " 'избранный президент',\n",
       " 'иностранных дел',\n",
       " 'конца года',\n",
       " 'коренных малочисленных',\n",
       " 'лет назад',\n",
       " 'лиги чемпионов',\n",
       " 'лошадиных сил',\n",
       " 'малочисленных народов',\n",
       " 'мвд россии',\n",
       " 'миллиона рублей',\n",
       " 'миллионов рублей',\n",
       " 'млн долларов',\n",
       " 'млн рублей',\n",
       " 'москва дек',\n",
       " 'москва декабря',\n",
       " 'народов севера',\n",
       " 'настоящее время',\n",
       " 'несколько дней',\n",
       " 'несколько лет',\n",
       " 'обновлено декабря',\n",
       " 'около тысяч',\n",
       " 'опубликовано декабря',\n",
       " 'отключен javascript',\n",
       " 'официальный представитель',\n",
       " 'первое место',\n",
       " 'первую очередь',\n",
       " 'поддерживает html',\n",
       " 'подписывайтесь канал',\n",
       " 'понедельник декабря',\n",
       " 'последнее время',\n",
       " 'правах рекламы',\n",
       " 'предварительной информации',\n",
       " 'предварительным данным',\n",
       " 'президент сша',\n",
       " 'президента сша',\n",
       " 'проигрывателя adobe',\n",
       " 'прошлого года',\n",
       " 'прошлой неделе',\n",
       " 'прошлом году',\n",
       " 'рабочих мест',\n",
       " 'различной степени',\n",
       " 'ранее сообщалось',\n",
       " 'результате дтп',\n",
       " 'речь идет',\n",
       " 'риа новости',\n",
       " 'российской федерации',\n",
       " 'самом деле',\n",
       " 'сегодняшний день',\n",
       " 'сих пор',\n",
       " 'следственного комитета',\n",
       " 'следующего года',\n",
       " 'следующем году',\n",
       " 'сообщает пресс-служба',\n",
       " 'сообщает риа',\n",
       " 'сообщили пресс-службе',\n",
       " 'социальной сети',\n",
       " 'стало известно',\n",
       " 'старая версия',\n",
       " 'степени тяжести',\n",
       " 'стоит отметить',\n",
       " 'сша дональд',\n",
       " 'таким образом',\n",
       " 'текущего года',\n",
       " 'тех пор',\n",
       " 'точки зрения',\n",
       " 'тура чемпионата',\n",
       " 'турнирной таблице',\n",
       " 'тысяч долларов',\n",
       " 'тысяч рублей',\n",
       " 'тысяч человек',\n",
       " 'уголовное дело',\n",
       " 'установлена старая',\n",
       " 'фото reuters',\n",
       " 'фото сайта',\n",
       " 'читайте также',\n",
       " 'это время',\n",
       " 'это значит',\n",
       " 'это очень',\n",
       " 'января года']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = sorted(tf_model.vocabulary_)\n",
    "display(len(vocab))\n",
    "display(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## кластеризируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018299992189866887"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.2168617334102432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.4142135623730954"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# оценки расстояний \n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "d = euclidean_distances(data_tf)\n",
    "\n",
    "display( d[d>0.].min(),d[d>0.].mean(),d.max(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.8 ms, sys: 36.7 ms, total: 111 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "data['cluster_id'] = DBSCAN(eps=.7,min_samples=3).fit(data_tf).labels_\n",
    "\n",
    "display( data['cluster_id'].drop_duplicates().count() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>count</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>465</td>\n",
       "      <td>science culture realty incident social auto economics reclama sport health tech woman politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>921</td>\n",
       "      <td>science culture realty incident social auto economics reclama sport health tech woman politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>science culture auto economics sport tech politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>culture social auto economics tech politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>science culture incident social auto economics sport tech woman politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>77</td>\n",
       "      <td>10</td>\n",
       "      <td>incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>79</td>\n",
       "      <td>3</td>\n",
       "      <td>incident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>incident auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>81</td>\n",
       "      <td>14</td>\n",
       "      <td>auto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_id  count  \\\n",
       "0           -1    465   \n",
       "1            0    921   \n",
       "2            1     25   \n",
       "3            2     17   \n",
       "4            3    120   \n",
       "..         ...    ...   \n",
       "78          77     10   \n",
       "79          78      5   \n",
       "80          79      3   \n",
       "81          80      3   \n",
       "82          81     14   \n",
       "\n",
       "                                                                                              tags  \n",
       "0   science culture realty incident social auto economics reclama sport health tech woman politics  \n",
       "1   science culture realty incident social auto economics reclama sport health tech woman politics  \n",
       "2                                               science culture auto economics sport tech politics  \n",
       "3                                                      culture social auto economics tech politics  \n",
       "4                         science culture incident social auto economics sport tech woman politics  \n",
       "..                                                                                             ...  \n",
       "78                                                                                        incident  \n",
       "79                                                                                        incident  \n",
       "80                                                                                        incident  \n",
       "81                                                                                   incident auto  \n",
       "82                                                                                            auto  \n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# номер кластера, количество объектов, метки объектов\n",
    "# (cluster=-1 - некластеризованные DBSCAN объекты) \n",
    "cluster_descr = pd.concat([\n",
    "        data[['cluster_id','tag']].groupby(['cluster_id'])['tag'].count(),\n",
    "        data[['cluster_id','tag']].groupby(['cluster_id'])['tag'].apply(lambda s: set(s)).apply(' '.join)\n",
    "    ],axis=1).reset_index()\n",
    "\n",
    "cluster_descr.columns = ['cluster_id','count','tags']\n",
    "\n",
    "display( cluster_descr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "      <th>cluster_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Жителей Полоцка приглашают поучаствовать в конкурсе на лучший новогодний тюнинг\\n\\n29 ноября 2016 в 9:04\\n\\nБЕЛТА\\n\\nВ Полоцке пройдет открытый конкурс на лучший новогодний авторестайлинг, сообщил...</td>\n",
       "      <td>auto</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>Инцидент с ребенком произошел в автобусе №77 в Орджоникидзевском районе Перми. Водитель пропустил остановку и высадил мальчика на мороз между остановочными пунктами в лесу.\\n\\nПо словам очевидцев,...</td>\n",
       "      <td>incident</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>10 Декабря `16 | 16:19\\n\\nВ четверг, 15 декабря, на киностудии \"Ленфильм\" (Каменноостровский проспект, 10) состоится торжественное открытие III Санкт-Петербургской выставки исторической литературы...</td>\n",
       "      <td>culture</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>Вашингтон, , 09:00 — REGNUM Последнее суперлуние (совпадение полнолуния с моментом наибольшего сближения Луны и Земли) в этом году можно будет наблюдать в ночь на 14 декабря, сообщили в пресс-служ...</td>\n",
       "      <td>science</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>ФедералПресс В Туве зарегистрирована ассоциация коренного малочисленного народа\\nтувинцев-тоджинцев ?Тос-Чадыр?  Управление министерства юстиции Республики Тува\\nзарегистрировало в качестве общест...</td>\n",
       "      <td>politics</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>ИА Dv-News (dv-news.com) Тувинцы-тоджинцы собрались в общественную\\nорганизацию Управление министерства юстиции Республики Тува зарегистрировало\\nв качестве общественной организации ассоциацию кор...</td>\n",
       "      <td>politics</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>20.07.2010. СеверИнфо (severinfo.ru) (Вологда) В Нарьян-Маре появится еще один\\nпамятник ИГ \"СеверИнфо\" Архангельская обл.  В Нарьян-Маре появится еще один\\nпамятник Закладной камень новому памятн...</td>\n",
       "      <td>culture</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>Двина Информ В Нарьян-Маре появится еще один памятник Закладной камень новому\\nпамятнику оленно-транспортным батальонам будет заложен в дни празднования\\n75-летия города Нарьян-Мара...  Об этом со...</td>\n",
       "      <td>culture</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         text  \\\n",
       "1258  Жителей Полоцка приглашают поучаствовать в конкурсе на лучший новогодний тюнинг\\n\\n29 ноября 2016 в 9:04\\n\\nБЕЛТА\\n\\nВ Полоцке пройдет открытый конкурс на лучший новогодний авторестайлинг, сообщил...   \n",
       "2245  Инцидент с ребенком произошел в автобусе №77 в Орджоникидзевском районе Перми. Водитель пропустил остановку и высадил мальчика на мороз между остановочными пунктами в лесу.\\n\\nПо словам очевидцев,...   \n",
       "2503  10 Декабря `16 | 16:19\\n\\nВ четверг, 15 декабря, на киностудии \"Ленфильм\" (Каменноостровский проспект, 10) состоится торжественное открытие III Санкт-Петербургской выставки исторической литературы...   \n",
       "2586  Вашингтон, , 09:00 — REGNUM Последнее суперлуние (совпадение полнолуния с моментом наибольшего сближения Луны и Земли) в этом году можно будет наблюдать в ночь на 14 декабря, сообщили в пресс-служ...   \n",
       "3076  ФедералПресс В Туве зарегистрирована ассоциация коренного малочисленного народа\\nтувинцев-тоджинцев ?Тос-Чадыр?  Управление министерства юстиции Республики Тува\\nзарегистрировало в качестве общест...   \n",
       "3093  ИА Dv-News (dv-news.com) Тувинцы-тоджинцы собрались в общественную\\nорганизацию Управление министерства юстиции Республики Тува зарегистрировало\\nв качестве общественной организации ассоциацию кор...   \n",
       "3132  20.07.2010. СеверИнфо (severinfo.ru) (Вологда) В Нарьян-Маре появится еще один\\nпамятник ИГ \"СеверИнфо\" Архангельская обл.  В Нарьян-Маре появится еще один\\nпамятник Закладной камень новому памятн...   \n",
       "3174  Двина Информ В Нарьян-Маре появится еще один памятник Закладной камень новому\\nпамятнику оленно-транспортным батальонам будет заложен в дни празднования\\n75-летия города Нарьян-Мара...  Об этом со...   \n",
       "\n",
       "           tag  cluster_id  \n",
       "1258      auto          62  \n",
       "2245  incident          62  \n",
       "2503   culture          62  \n",
       "2586   science          62  \n",
       "3076  politics          62  \n",
       "3093  politics          62  \n",
       "3132   culture          62  \n",
       "3174   culture          62  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display( data.query('cluster_id==62') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
